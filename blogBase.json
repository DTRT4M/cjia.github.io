{"singlePage": [], "startSite": "", "filingNum": "", "onePageListNum": 15, "commentLabelColor": "#006b75", "yearColorList": ["#bc4c00", "#0969da", "#1f883d", "#A333D0"], "i18n": "CN", "themeMode": "manual", "dayTheme": "light", "nightTheme": "dark", "urlMode": "pinyin", "script": "", "style": "", "head": "", "indexScript": "", "indexStyle": "", "bottomText": "", "showPostSource": 1, "iconList": {}, "UTC": 8, "rssSplit": "sentence", "exlink": {}, "needComment": 1, "allHead": "", "title": "Chenxu JIA's Blog\uff08\u8d3e\u6668\u65ed\u7684\u535a\u5ba2\uff09", "subTitle": "Statistic, Economic, and Finance", "avatarUrl": "https://github.githubassets.com/favicons/favicon.svg", "GMEEK_VERSION": "last", "postListJson": {"P1": {"htmlDir": "docs/post/Multiple Testing.html", "labels": ["documentation"], "postTitle": "Multiple Testing", "postUrl": "post/Multiple%20Testing.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/1", "commentNum": 0, "wordCount": 3593, "description": "# False discovery\r\nConsider these hypothesis testing questions:\r\n$$H_{0j} vs H_{1j}, j=1,2...,n$$.\r\nWe want to test these an the same time, then we will receive these four results:\r\n\r\nTable 1:Four potential outcomes in multiple hypothesis testing\r\n\r\n<table>\r\n\t<tbody>\r\n\t\t<tr>\r\n\t\t\t<th> </th>\r\n\t\t\t<th>Fail to reject $H_{0}$</th>\r\n\t\t\t<th>Reject $H_0$</th>\r\n\t\t\t<th>Overall</th>\r\n\t\t</tr>\r\n\t\t<tr>\r\n\t\t\t<td>$$H_0$$ is true</td>\r\n\t\t\t<td>$V$</td>\r\n\t\t\t<td>$U$</td>\r\n\t\t\t<td>$p_0$</td>\r\n\t\t</tr>\r\n\t\t<tr>\r\n\t\t\t<td>$$H_0$$ is false</td>\r\n\t\t\t<td>$S$</td>\r\n\t\t\t<td>$T$</td>\r\n\t\t\t<td>$P1$</td>\r\n\t\t</tr>\r\n\t\t<tr>\r\n\t\t\t<td>Overall</td>\r\n\t\t\t<td>$p-R$</td>\r\n\t\t\t<td>$R$</td>\r\n\t\t\t<td>$\\mathcal{D}=\\mathcal{D}_{0}+\\mathcal{L}$</td>\r\n\t\t</tr>\r\n\t</tbody>\r\n</table>\r\n\r\nFrom this table, we could find out there are two types of error in multiple testing:\r\n+ $p_0$ = # {Null}\r\n+ $p_1$ = # {Alternative}\r\n+ U = # {Fales discovery/ False postive} $\\longleftarrow$ type-I error\r\n+ S = # {False negative} $\\longleftarrow$  type-II error\r\n+ T = # {True positive}\r\n+ R = # {Total rejection}\r\nTherefore question is that --- How to control typr-I error?\r\n\r\n\r\n\r\n# Familywise Error Rate(FWER)\r\nThe traditional method to control gobal hypothesis test hope to strictlt control familywise error rate\r\n$$FEWR = P(U\\geq 1) \\leq \\alpha,$$\r\nwhich means the probability of controlling for the rejection of at least one of the true original hypotheses does not exceed a given significance level $\\alpha$.\r\n\r\n\r\n\r\n## Benforonni correction\r\n\r\nStep 1: For each hypothesis $${H_{0j}}_{j=1}^p$$, construct the test statistic $$\\{T_j\\}_j=1^p$$, compute the p-value $$\\{p_j\\}_j=1^p$$\r\n\r\nStep 2: For $$j=1,\\cdots,p$$, reject the corresponding original hypothesis $$h_{0j}$$, if $$p_j\\leq \\frac{\\alpha}{p}$$. \r\n\r\nDefine $S_{0}={j:H_{0j}}$ is true , and the Benforonni correction method satisfies\r\n\r\n$$\\text{FWER}=\\mathbb{P}\\left(\\bigcup_{j\\in S_0}\\{p_j\\leq\\alpha/p\\}\\right)\\leq\\sum_{j\\in S_0}\\mathbb{P}(p_j\\leq \\alpha/p) = p_0 \\frac{\\alpha}{p}<\\alpha.$$\r\n\r\nTwo flaws in the FWER criterion: \r\n+ Theorem 1 states that the Benforonni correction will actually control the FEWR below the level of $p_0 \\frac{\\alpha}{p}$. The Benforonni correction is conservative when the difference between $p_0$ and $p$ is large;\r\n+ When the scale of multiple tests $p$ is large or even divergent, the rejection threshold $\\alpha/p$ of Benforonni correction degenerates and tends to cause the FWER criterion to be too strict and not to reject any hypothesis .\r\n\r\nTherefore, we need a new method to improve this situation.\r\n\r\n# False Discovery Rate\r\nBenjamini and Hochberg(1995) suggest that set False Discovery Rate(FDR) as standard of type-I error control, rather than FWER.\r\n\r\n## Def (FDR):\r\n\r\n$$FDR \\equiv E(FDP) = E\\left[\\frac{U}{R \\vee 1}\\right] ,$$\r\nwhere U is Fales discovery/ False postive, T is true positive, and R is total rejections.\r\n\r\nNow we consider how to control FDR.\r\n\r\n# Benjamini-Hochberg Method\r\nFor a given FDR control level $\\( q \\in (0,1) \\)$, the BH method's algorithm is as follows:\r\n\r\n**Step 1:** For the $\\( p \\)$-dimensional hypotheses $\\( \\{H_{0j}\\}_{j=1}^p \\)$, construct the test statistics $\\( \\{T_j\\}_{j=1}^p \\) $and calculate the corresponding p-values $\\( \\{p_j\\}_{j=1}^p \\)$.\r\n\r\n**Step 2:** Sort the obtained p-values in ascending order to get: $\\( p_{(1)} \\leq \\cdots \\leq p_{(p)} \\)$.\r\n\r\n**Step 3:** Select a data-adaptive threshold value\r\n\r\n$$k^* = \\max_{1 \\leq k \\leq p} \\{ k : p_{(k)}{ \\leq \\frac{q}{p} k}};$$\r\n\r\n**Step 4:** For $\\( j = 1, \\cdots, p \\), if \\( p_j \\leq p(k^*) \\)$, reject the corresponding null hypothesis $\\( H_{0j} \\)$.\u3002", "top": 0, "createdAt": 1726732267, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-09-19", "dateLabelColor": "#bc4c00"}, "P2": {"htmlDir": "docs/post/Bayesian Multiple Testing.html", "labels": ["documentation"], "postTitle": "Bayesian Multiple Testing", "postUrl": "post/Bayesian%20Multiple%20Testing.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/2", "commentNum": 0, "wordCount": 1888, "description": "# The prior and posterior distributions\r\nIn the absence of strong prior information about $V$ and $\\sigma^2$, we suggest use of\r\n\r\n$$\\pi(V,\\sigma^2)=(V+\\sigma^2)^{-2}.$$\r\n\r\nThe motivation for this choice follows from writing\r\n\r\n$$\\pi(V,\\sigma^2)=\\pi(V\\mid\\sigma^2)\\pi(\\sigma^2)\\equiv\\frac1{\\sigma^2}\\left(1+\\frac V{\\sigma^2}\\right)^{-2}\\frac1{\\sigma^2}.$$\r\n\r\n# The prior on p\r\nAn obvious objective choice of this prior is $\\pi(p)=1.$ Typically, however, one does have strong prior information about $p$ and, often, this information is that $p$ is large (i.e., that most of the $\\mu_i$ are zero). A convenient functional form that represents this type of information is\r\n\r\n$$\\pi(p)=(\\alpha+1)p^\\alpha$$\r\n\r\nwhere $\\alpha$ is an adjustable parameter allowing one to control how much of $\\pi(p)\u2019$s mass is concentrated near 1. Note the case of $\\alpha=0$, which defaults back to the uniform prior.\r\n\r\nOne simple way to specify $\\alpha$ would be to make a \u2018best guess\u2019 $\\hat{p}$,for $p$, and interpret this guess as the prior median. Solving for $\\alpha$ leads to the choice\r\n\r\n$$\\alpha=\\frac{\\log(.5)}{\\log(\\hat{p})}-1.$$\r\n\r\nAs long as one does not choose $\\hat{p}$ to be extremely close to 1,the resulting prior is not overly concentrated. For example, suppose the best guess for $p$ is .9,leading to $x=5.58.$ The resulting prior has f\u0131rst decile of .7,f\u0131rst quartile of .81, and third quartile of .96, reflecting a reasonable amount of variation.\r\n\r\n# The posterior distribution\r\nUnder the above modeling assumptions, the posterior density of $\\Theta=(p,V,\\sigma^{2},\\gamma,\\mu)$ is\r\n\r\n$$\\pi(\\Theta\\mid x)=C_1^{-1}\\cdot f(x\\mid\\sigma^2,\\gamma,\\mu)\\cdot\\left[\\prod_{i:\\gamma_i=1}^M\\mathrm{N}(\\mu_i\\mid0,V)\\right]\\cdot\\pi(\\gamma\\mid p)\\cdot\\pi(V,\\sigma^2)\\cdot\\pi(p),$$\r\n\r\nwhere $\\pi(\\gamma\\mid p)=\\prod_{i=1}^{M}p^{1-\\gamma_{i}}(1-p)^{\\gamma_{i}}$ and $C_{1}$ is the normalization constant.\u3002", "top": 0, "createdAt": 1731053703, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-08", "dateLabelColor": "#bc4c00"}, "P3": {"htmlDir": "docs/post/jin-pai-jiu-ye- - -cai-fang-quan-wen.html", "labels": ["documentation"], "postTitle": "\u91d1\u724c\u5c31\u4e1a | \u91c7\u8bbf\u5168\u6587", "postUrl": "post/jin-pai-jiu-ye-%20-%20-cai-fang-quan-wen.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/3", "commentNum": 0, "wordCount": 1740, "description": "# \u60a8\u662f\u4ec0\u4e48\u65f6\u5019\u51b3\u5b9a\u7533\u8bf7\u6e2f\u6821\u7684\uff1f\u53c8\u662f\u5982\u4f55\u8003\u8651\u7684\u5462\uff1f\r\n\u5176\u5b9e\u6211\u4e00\u5f00\u59cb\u5e76\u6ca1\u6709\u7559\u5b66\u7684\u6253\u7b97\uff0c\u4e00\u95e8\u5fc3\u601d\u60f3\u7684\u662f\u8003\u7814\u7684\u4e8b\u60c5\u3002", "top": 0, "createdAt": 1731296767, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P4": {"htmlDir": "docs/post/Confidence Distribution.html", "labels": ["documentation"], "postTitle": "Confidence Distribution", "postUrl": "post/Confidence%20Distribution.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/4", "commentNum": 0, "wordCount": 4398, "description": "# Concept\r\n**Definition (CD and asymptotic CD)** A function $H_{n}(\\cdot)=H_{n}(x,\\cdot)$ on $\\mathcal{X}\\times\\Theta\\to[0,1]$ is calleda CD for a parameter, if (1) For each given $x\\in\\mathcal{X},H_{n}(\\cdot)$ is a (continuous) cumulative distribution function on O; (2)At the true parameter value $\\theta=\\theta_{0}$ \uff0c $H_{n}(\\theta_{0})\\equiv H_{n}(x,\\theta_{0})$ ,as a function of the sample 2L follows the uniform distribution $U(0,1).$ In addition, the function $H_{n}(\\cdot)$ is called an asymptoticCDif condition (2\uff09is replaced by (2')At the true parameter $\\theta=\\theta_{0}$ \uff0c $H_{n}(\\theta_{0})\\stackrel{d}{\\rightarrow}U(0,1)$ 0.8 $Tl\\rightarrow\\mathbf{x}$\r\n\r\n\r\n\r\n# Example\r\n**Example 1 (Singh et al.,2005)** Let $\\tilde{\\theta}$ be a consistent estimator of $\\theta$ .For bootstrap, the distribution of $\\hat{\\theta}^\\*-\\theta$ is estimated by the bootstrap distribution $\\hat{\\theta}^{\\*}-\\hat{\\theta}$ where $\\tilde{\\theta}^{\\*}$ is the estimator of $\\theta$ computed on a bootstrap sample (Efron and Tibshirani, 1993). An asymptotic CD for $\\theta$ is given by $H_{n}(\\theta)=1-Pr(\\hat{\\theta}^{\\*}-\\hat{\\theta}\\leq\\hat{\\theta}-\\theta) = Pr(\\hat{\\theta}^{\\*} \\geq2\\hat{\\theta}-\\theta)$ .In addition, when the limiting distribution of normalized $\\tilde{\\theta}$ is symmetric, the raw bootstrap distribution $H_{n}(\\theta)=1-Pr(\\hat{\\theta}-\\hat{\\theta}^{\\*}\\leq\\hat{\\theta}-\\theta)=Pr(\\hat{\\theta}^{\\*}\\leq\\theta)$ is also an asymptotic CD.\r\n\r\n**Example 2** Suppose we are interested in the location parameter $\\theta$ of a continuous distribution.When the distribution $F$ is symmetric, i.e., $F(\\theta-y)=1-F(\\theta+y)$ \uff0c $\\theta$ is the median.The Wilcoxon rank test for $H_{0}:\\theta=t$ \uff0c $H_{1}:\\theta\\neq t$ is based on the summation of signed ranks of $Y_{i}-t$ ,ie.,the test statistic $W=\\sum_{i=1}^{n}Z_{i}R_{i}$ ,where $R_{i}$ is the rank of $\\left|Y_{i}-t\\right|$ \uff0c $Z_{i}$ is an indicator variable with 1 if $Y_{i}-t>0$ and -1 otherwise. Denote by $p(t)$ the $Y$ -value associated with the Wilcoxon rank test for $H_{0}:\\theta=t$ \uff0c $H_{1}:\\theta\\neq t$ When $t$ varies in $(-\\infty,\\infty)$ ,\uff0cthe $P$ -value $p(t)$ is referred to as a $P$ -value function.We can prove that the $P$ -value function $p(t)$ is an asymptotic CD (Xie and Singh, 2013). Figures 2 provides illustrations of the asymptotic CD density $p^{\\prime}(t)$ ,the asymptotic CD function $p(t)$ and the asymptotic CV $2min({p(t),1-p(t)\\})$ for two sample sizes. The data are generated from $N(0,1)$ with sample sizes $n=10$ and 100, respectively\r\n\r\n\r\n\r\n# CD-based inference\r\n**Point estimation The natural choices of point estimators of the parameter** Given a CD $H_n(\\cdot)$, include \r\n\r\n(i) the median $\\widetilde{\\theta}_n=H_n(1/2);$ \r\n\r\n(ii) the mean $\\bar{\\theta}_{n}=\\int_{\\theta\\in\\Theta}\\theta dH_{n}(\\theta);$ and\r\n\r\n(iii) the mode $\\widehat{\\theta}_n=\\arg\\max_{\\theta\\in\\Theta}h_n(\\theta)$, where $h_n(\\theta)=dH_n(\\theta)/d\\theta$ is the confidence density function. Under some moderate conditions, these three point estimators are consistent.\r\n\r\nTo further understand these three types of estimators, the median $\\widetilde{\\theta}_{n}$ is an unbiased estimator with \r\n\r\n$Pr_{\\theta_0}(\\widetilde{\\theta}_{n} \\leq \\theta_0) = Pr_{\\theta_0}(1/2 \\leq H_n(\\theta_0))=1/2$\r\n\r\nThe mean $\\bar{\\theta}_n$ can be viewed as a frequentist analog of Bayesian estimator under the squared loss function; The mode $\\widehat{\\theta}_n$ matches with the maximum likelihood estimator if the confidence densitv is from a normalized likelihood function (Xie and Singh, 2013)\r\n\r\n**Confidence interval** As discussed in Section $\\boxed2.1$, in a confidence curve, a line across the $y$-axis of the significance level $\\alpha$ intersects with the confidence curve at two points, and these two points correspond to an $1-\\alpha$ level, equal tailed, two-sided confidence interval for $\\theta$, i.e., $(H_n^{-1}(\\alpha/2),H_n^{-1}(1-\\alpha/2)).$ Furthermore, $(-\\infty,H_n^{-1}(1-\\alpha)]$ and $[H_n^{-1}(\\alpha),\\infty)$ are one-sided $1-\\alpha$ level confidence intervals for the parameter $\\theta.$\r\n\r\n**Hypothesis testing** From a CD, one can obtain p-values for various hypothesis testing problems The natural thinking is to measure the support that $H_n(\\cdot)$ lends to a null hypothesis (Fraser, 1991) Xie and Singh (2013) summarized making inference for hypothesis testing from a CD in the following theorem.\u3002", "top": 0, "createdAt": 1731317551, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P5": {"htmlDir": "docs/post/Note of A tiny review on e-values and e-processes - by Ruodu Wang.html", "labels": ["documentation"], "postTitle": "Note of A tiny review on e-values and e-processes - by Ruodu Wang", "postUrl": "post/Note%20of%20A%20tiny%20review%20on%20e-values%20and%20e-processes%20-%20by%20Ruodu%20Wang.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/5", "commentNum": 0, "wordCount": 3816, "description": "# Def (e-variable)\r\nE-variable for a hypothesis $H$ is a $[0, \\infty]$-valued random variable satisfied \r\n\r\n$$E^{Q}(E) \\leq 1,$$\r\n\r\nwhere $Q$ is the only one probability measure to represent $H$.\r\n\r\n**Remark 1**: This definition do not give a unnique method to conduct a e-variable, which means it is open to methods that can satisfy it. This point is vert crucial for us to understand how to test hypothesis by e-variable.\r\n\r\n\r\n\r\n# Basic examples and properties\r\nFor the simplest example, suppose that we are testing a simple hypothesis $Q_0$ versus a simple hypothesis $Q_1$, where $Q_1$ is absolutely continuous with respect to $Q_0.$ For this setting, a natural e-variable is the likelihood ratio $E$ = d$Q_1/$d$Q_0(X)$ where $X$ is the observed data. It is straightforward to verify that $E\\geq0$ and it satisfes $\\mathbb{E}^Q_0[E]=1.$ If we observe iid data $X_1,X_2,\\ldots$ sequentially, then the likelihood ratio process $M$ given by\r\n\r\n$$M_0=1\\quad\\mathrm{~and~}\\quad M_t=\\prod_{k=1}^t\\frac{\\mathrm{d}Q_1}{\\mathrm{d}Q_0}(X_k)\\text{ for }t=1,2,\\ldots $$\r\n\r\nis an e-process adapted to the filtration generated by the data. Moreover, we can easily see that $M$ is a martingale. Indeed, when testing simple hypotheses, it is optimal in a natural sense to use a martingale to construct e-processes. For composite hypotheses, the situation is much more complicated, as non-trivial composite martingales may not exist while non-trivial e-processes may exist (Ramdas et al. (2020)).\r\n\r\nLet $E$ be an e-variable tor $H$. An important property ot e-variables is the inequality $Q(E\\geq1/\\alpha)\\leq\\alpha$ for any $\\alpha\\in(0,1)$ and $Q\\in H$, due to Markov's inequality. Moreover, for any non-negative supermartingale $M$ under $Q$ with $M(0)=1$, Ville $(1939)\u2019$s inequality gives\r\n\r\n$$Q\\left(\\sup_{t=0,1,...,T}M_t\\geq\\frac1\\alpha\\right)\\leq\\alpha,\\quad\\alpha\\in(0,1);$$\r\n\r\nhere $T$ may be finite or infnite. Moreover, any e-process for $H$ is dominated by a class of supermartingales $M^Q$ with initial value 1 for $Q\\in H$, all with respect to the same filtration (Ramdas et al. (2020)). This insight implies that tests formulated by rejecting the null hypothesis if an e-process goes above $1/\\alpha$ are anytime-$valid;$ that is, its type-I error is controlled at $\\alpha$ regardless of the stopping rule.\r\n\r\n**Remark 2:** The supermartingales $M^Q$ does not mean it is the sequence of likelihood ratio, of course. Just we disscuss in **Remark 1** which the definition of e-variable is open to methods that can satisfy it. Therefore if every element of one supermartingale all can satisfy the definition of e-variable, we can say this supermartingales is a e-process which can be used to do hypothesis testing.\r\n\r\n\r\n\r\n# Calibrators\r\nCalibrators, under various names, are studied by Shafer et al. (2011), Shafer (2021) and Vovk and Wang (2021). A decreasing function $f:[0,1]\\to[0,\\infty]$ is an admissible p-to-e calibrator if and only if $f$ is upper semicontinuous, $f(0)=\\infty$, and $\\int_0^1f=1.$ Simple examples of p-to-e calibrators are $f(p)=\\kappa p^{\\kappa-1}$ for some $\\kappa\\in(0,1)$ and $f(p)=p^{-1/2}-1$ (Shafer's). On the other hand, the only admissible e-to-p calibrator is given by $f:[0,\\infty]\\to[0,1],f(e)=\\min(1/e,1);$ this is again due to Markov's inequality. Hence, for any e-variable $E,1/E$ truncated at 1 is a p-variable. If further $E$ has a decreasing density on $(0,\\infty)$, then $1/(2E)$ is a p-variable (Wang (2023)). Converting a p-value to an e-value using a p-to-e calibrator and then back to p-value using an e-to-p calibrator generally loses quite a lot of evidence. For instance starting with $p=0.01$, a conversion with the p-to-e calibrator $p\\mapsto p^{-1/2}-1$ gives $e=9$, and another conversion with the e-to-p calibrator $e\\mapsto\\min(1/e,1)$ yields $p^\\prime=1/9.$\u3002", "top": 0, "createdAt": 1731317710, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P6": {"htmlDir": "docs/post/Bayesian spline.html", "labels": ["documentation"], "postTitle": "Bayesian spline", "postUrl": "post/Bayesian%20spline.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/6", "commentNum": 0, "wordCount": 131, "description": "This is R  code for solving $\\eta$ of Bayesian spline.\r\n[R Code.zip](https://github.com/user-attachments/files/17700501/R.Code.zip)\u3002", "top": 0, "createdAt": 1731319041, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P7": {"htmlDir": "docs/post/Deep learning for image recognition code.html", "labels": ["documentation"], "postTitle": "Deep learning for image recognition code", "postUrl": "post/Deep%20learning%20for%20image%20recognition%20code.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/7", "commentNum": 0, "wordCount": 159, "description": "This is a python code about deep learning for image recognition.\r\n[DeepLearning.zip](https://github.com/user-attachments/files/17703690/DeepLearning.zip)\r\n\r\n\r\n\u3002", "top": 0, "createdAt": 1731319605, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P8": {"htmlDir": "docs/post/Rough Set Code.html", "labels": ["documentation"], "postTitle": "Rough Set Code", "postUrl": "post/Rough%20Set%20Code.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/8", "commentNum": 0, "wordCount": 114, "description": "This is a code about rough set.\r\n[RoughSet.zip](https://github.com/user-attachments/files/17700634/RoughSet.zip)\r\n\u3002", "top": 0, "createdAt": 1731319723, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P9": {"htmlDir": "docs/post/Papers about Digital Transformation.html", "labels": ["documentation"], "postTitle": "Papers about Digital Transformation", "postUrl": "post/Papers%20about%20Digital%20Transformation.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/9", "commentNum": 0, "wordCount": 281, "description": "[\u6570\u5b57\u5316\u8f6c\u578b\u5bf9\u78b3\u6392\u653e\u7684\u5f71\u54cd\u673a\u5236\u7814\u7a76\uff1a\u6765\u81ea\u5de5\u4e1a\u4f01\u4e1a\u7684\u7ecf\u9a8c\u8bc1\u636e.pdf](https://github.com/user-attachments/files/17700888/default.pdf)\r\n\r\n[\u6570\u5b57\u5316\u8f6c\u578b\u4f1a\u5f71\u54cd\u4f01\u4e1a\u5e76\u8d2d\u884c\u4e3a\u5417\uff1f.pdf](https://github.com/user-attachments/files/17700889/default.pdf)\r\n\r\nP.S.: The scale of data is too large to upload here, and I can send by email if you need.\u3002", "top": 0, "createdAt": 1731321123, "style": "", "script": "", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-11-11", "dateLabelColor": "#bc4c00"}, "P10": {"htmlDir": "docs/post/PDE - Energy Method.html", "labels": ["documentation"], "postTitle": "PDE | Energy Method", "postUrl": "post/PDE%20-%20Energy%20Method.html", "postSourceUrl": "https://github.com/DTRT4M/cjia.github.io/issues/10", "commentNum": 0, "wordCount": 2379, "description": "# Preparation\r\nConsider a heat equation \r\n\r\n$$\r\n\\begin{align}\r\n\\begin{cases}\r\n&u_t-Du_{xx}=0,\\quad in\\ [0, L] \\times [0, \\infty] \\\\\r\n&u(0, x)=g(x),\\quad for\\ x\\in [0, L]\\\\\r\n&u(0, t)=u(L, t),\\quad for\\ t>0\r\n\\end{cases}\r\n\\end{align}\r\n$$\r\n\r\nBy multiplying the first equation by u, we get\r\n\r\n$$\r\nuu_t-Duu_{xx}=0 \r\n$$\r\n\r\nThen we integrate both sides in $[0, L]$, we get\r\n\r\n$$\\int_{o}^{L} uu_tdx - D \\int_{0}^{L}uu_{xx}dx = 0$$\r\n\r\nNow we focus on $\\int_{o}^{L}uu_tdx$, we obtain\r\n\r\n$$\r\n\\int_{o}^{L}uu_tdx = \\frac{1}{2}\\int_{0}^{L}\\frac{d}{dt}(u^2)dx = \\frac{d}{dt}(\\frac{1}{2}\\int_{0}^{L}u^2dx).\r\n$$\r\n\r\nThen we focus on $\\int_{0}^{L}uu_{xx}dx$, we have\r\n```math\r\n\\int_{0}^{L}uu_{xx}dx = uu_{x}|_{0}^{L} - \\int_{0}^{L}u_{x}^{2}dx = -\\int_{o}^{L} u_{x}^{2}dx\r\n```\r\n\r\nwhere we used boundary condition. Therefore we have\r\n\r\n$$\r\n\\frac{d}{dt}(\\frac{1}{2}\\int_{0}^{L}u^2dx) = -D\\int_{0}^{L}u_{x}^{2}dx \\leq 0.\r\n$$\r\n\r\nWe call $\\varepsilon(t):=\\frac{1}{2}\\int_{0}^{L}u^2dx$ is the *energy of the system*, and we know \r\n\r\n$$\r\n\\frac{d}{dt} \\varepsilon(t) = -D\\int_{0}^{L}u_{x}^{2}dx \\leq 0,\r\n$$\r\n\r\nwhich means the energy function is non-increasing in time.\r\n\r\n# Proof of Uniqueness\r\nWe want to prove this heat equation have uniqueness solution. For it, we condsider $u, v$ is two solutions of $(1)$, then $w:=w-v$. By using the linearity of heat equation, we know $w$ satisfy: \r\n\r\n$$\r\n\\begin{align}\r\n\\begin{cases}\r\n&w_t-Dw_{xx}=0,\\ in\\ [0, L] \\times [0, \\infty] \\\\\r\n&w(0, x)=0, \\ for\\ x\\in [0, L] \\\\\r\n&w(0, t)=0, \\ for\\ t>0\r\n\\end{cases}\r\n\\end{align}\r\n$$\r\n\r\n> Recall (Heat Equation):\r\n```math\r\n\\begin{align}\r\n\\begin{cases}\r\n&u_t-Du_{xx}=0,\\ in\\ [0, L] \\times [0, \\infty] \\\\\r\n&u(0, x)=g(x), \\ for\\ x\\in [0, L]  \\\\\r\n&u(0, t)=u(L, t), \\ for\\ t>0\r\n\\end{cases}\r\n\\end{align}\r\n```\r\n\r\nSo we have \r\n\r\n$$\r\n\\frac{d}{dt} \\varepsilon(t) = \\frac{d}{dt}(\\frac{1}{2}\\int_{o}^{L}w(x, t)^2dx) \\leq 0,\r\n$$\r\n\r\nand \r\n\r\n$$\r\n\\int_{o}^{L}w^2(x, 0)dx = 0,\r\n$$\r\n\r\nsince the initial codition is the null function. \r\n\r\nClearly, \r\n\r\n$$\r\n\\int_{o}^{L}w^2(x, t)dx \\geq 0 \\quad for \\ t \\geq 0,\r\n$$\r\n\r\nsince $w^2$ is non-negative. Therefore we have\r\n\r\n$$\r\n\\int_{o}^{L}w^2(x, t)dx = 0 \\quad for \\ t \\geq 0,\r\n$$\r\n\r\nwhich means $w^2(x, t)=0 \\Rightarrow w(x,t)=0$. \r\n> Recall: $\\int_{o}^{L}w^2(x, 0)dx = 0$; $\\frac{d}{dt} \\varepsilon(t) = \\frac{d}{dt}(\\frac{1}{2}\\int_{o}^{L}w(x, t)^2dx) \\leq 0$\r\n\r\nThus $(1)$ admit a unique solution. \u3002", "top": 0, "createdAt": 1733316889, "style": "", "script": "<script>MathJax = {tex: {inlineMath: [[\"$\", \"$\"]]}};</script><script async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>", "head": "", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "createdDate": "2024-12-04", "dateLabelColor": "#bc4c00"}}, "singeListJson": {}, "labelColorDict": {"bug": "#d73a4a", "documentation": "#0075ca", "duplicate": "#cfd3d7", "enhancement": "#a2eeef", "good first issue": "#7057ff", "help wanted": "#008672", "invalid": "#e4e669", "question": "#d876e3", "wontfix": "#ffffff"}, "displayTitle": "Chenxu JIA's Blog\uff08\u8d3e\u6668\u65ed\u7684\u535a\u5ba2\uff09", "faviconUrl": "https://github.githubassets.com/favicons/favicon.svg", "ogImage": "https://github.githubassets.com/favicons/favicon.svg", "primerCSS": "<link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />", "homeUrl": "https://DTRT4M.github.io/cjia.github.io", "prevUrl": "disabled", "nextUrl": "disabled"}