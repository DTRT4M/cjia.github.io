<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Chenxu JIA's Blog（贾晨旭的博客）</title><link>https://DTRT4M.github.io/cjia.github.io</link><description>Statistic, Economic, and Finance</description><copyright>Chenxu JIA's Blog（贾晨旭的博客）</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://DTRT4M.github.io/cjia.github.io</link></image><lastBuildDate>Mon, 11 Nov 2024 09:35:40 +0000</lastBuildDate><managingEditor>Chenxu JIA's Blog（贾晨旭的博客）</managingEditor><ttl>60</ttl><webMaster>Chenxu JIA's Blog（贾晨旭的博客）</webMaster><item><title>Note of A tiny review on e-values and e-processes - by Ruodu Wang</title><link>https://DTRT4M.github.io/cjia.github.io/post/Note%20of%20A%20tiny%20review%20on%20e-values%20and%20e-processes%20-%20by%20Ruodu%20Wang.html</link><description># Def (e-variable)&#13;
E-variable for a hypothesis $H$ is a $[0, \infty]$-valued random variable satisfied &#13;
&#13;
$$E^{Q}(E) \leq 1,$$&#13;
&#13;
where $Q$ is the only one probability measure to represent $H$.&#13;
&#13;
**Remark 1**: This definition do not give a unnique method to conduct a e-variable, which means it is open to methods that can satisfy it. This point is vert crucial for us to understand how to test hypothesis by e-variable.&#13;
&#13;
&#13;
&#13;
# Basic examples and properties&#13;
For the simplest example, suppose that we are testing a simple hypothesis $Q_0$ versus a simple hypothesis $Q_1$, where $Q_1$ is absolutely continuous with respect to $Q_0.$ For this setting, a natural e-variable is the likelihood ratio $E$ = d$Q_1/$d$Q_0(X)$ where $X$ is the observed data. It is straightforward to verify that $E\geq0$ and it satisfes $\mathbb{E}^Q_0[E]=1.$ If we observe iid data $X_1,X_2,\ldots$ sequentially, then the likelihood ratio process $M$ given by&#13;
&#13;
$$M_0=1\quad\mathrm{~and~}\quad M_t=\prod_{k=1}^t\frac{\mathrm{d}Q_1}{\mathrm{d}Q_0}(X_k)\text{ for }t=1,2,\ldots $$&#13;
&#13;
is an e-process adapted to the filtration generated by the data. Moreover, we can easily see that $M$ is a martingale. Indeed, when testing simple hypotheses, it is optimal in a natural sense to use a martingale to construct e-processes. For composite hypotheses, the situation is much more complicated, as non-trivial composite martingales may not exist while non-trivial e-processes may exist (Ramdas et al. (2020)).&#13;
&#13;
Let $E$ be an e-variable tor $H$. An important property ot e-variables is the inequality $Q(E\geq1/\alpha)\leq\alpha$ for any $\alpha\in(0,1)$ and $Q\in H$, due to Markov's inequality. Moreover, for any non-negative supermartingale $M$ under $Q$ with $M(0)=1$, Ville $(1939)’$s inequality gives&#13;
&#13;
$$Q\left(\sup_{t=0,1,...,T}M_t\geq\frac1\alpha\right)\leq\alpha,\quad\alpha\in(0,1);$$&#13;
&#13;
here $T$ may be finite or infnite. Moreover, any e-process for $H$ is dominated by a class of supermartingales $M^Q$ with initial value 1 for $Q\in H$, all with respect to the same filtration (Ramdas et al. (2020)). This insight implies that tests formulated by rejecting the null hypothesis if an e-process goes above $1/\alpha$ are anytime-$valid;$ that is, its type-I error is controlled at $\alpha$ regardless of the stopping rule.&#13;
&#13;
**Remark 2:** The supermartingales $M^Q$ does not mean it is the sequence of likelihood ratio, of course. Just we disscuss in **Remark 1** which the definition of e-variable is open to methods that can satisfy it. Therefore if every element of one supermartingale all can satisfy the definition of e-variable, we can say this supermartingales is a e-process which can be used to do hypothesis testing.&#13;
&#13;
&#13;
&#13;
# Calibrators&#13;
Calibrators, under various names, are studied by Shafer et al. (2011), Shafer (2021) and Vovk and Wang (2021). A decreasing function $f:[0,1]\to[0,\infty]$ is an admissible p-to-e calibrator if and only if $f$ is upper semicontinuous, $f(0)=\infty$, and $\int_0^1f=1.$ Simple examples of p-to-e calibrators are $f(p)=\kappa p^{\kappa-1}$ for some $\kappa\in(0,1)$ and $f(p)=p^{-1/2}-1$ (Shafer's). On the other hand, the only admissible e-to-p calibrator is given by $f:[0,\infty]\to[0,1],f(e)=\min(1/e,1);$ this is again due to Markov's inequality. Hence, for any e-variable $E,1/E$ truncated at 1 is a p-variable. If further $E$ has a decreasing density on $(0,\infty)$, then $1/(2E)$ is a p-variable (Wang (2023)). Converting a p-value to an e-value using a p-to-e calibrator and then back to p-value using an e-to-p calibrator generally loses quite a lot of evidence. For instance starting with $p=0.01$, a conversion with the p-to-e calibrator $p\mapsto p^{-1/2}-1$ gives $e=9$, and another conversion with the e-to-p calibrator $e\mapsto\min(1/e,1)$ yields $p^\prime=1/9.$。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/Note%20of%20A%20tiny%20review%20on%20e-values%20and%20e-processes%20-%20by%20Ruodu%20Wang.html</guid><pubDate>Mon, 11 Nov 2024 09:35:10 +0000</pubDate></item><item><title>Confidence Distribution</title><link>https://DTRT4M.github.io/cjia.github.io/post/Confidence%20Distribution.html</link><description># Concept&#13;
**Definition (CD and asymptotic CD)** A function $H_{n}(\cdot)=H_{n}(x,\cdot)$ on $\mathcal{X}\times\Theta\to[0,1]$ is calleda CD for a parameter, if (1) For each given $x\in\mathcal{X},H_{n}(\cdot)$ is a (continuous) cumulative distribution function on O; (2)At the true parameter value $\theta=\theta_{0}$ ， $H_{n}(\theta_{0})\equiv H_{n}(x,\theta_{0})$ ,as a function of the sample 2L follows the uniform distribution $U(0,1).$ In addition, the function $H_{n}(\cdot)$ is called an asymptoticCDif condition (2）is replaced by (2')At the true parameter $\theta=\theta_{0}$ ， $H_{n}(\theta_{0})\stackrel{d}{\rightarrow}U(0,1)$ 0.8 $Tl\rightarrow\mathbf{x}$&#13;
&#13;
&#13;
&#13;
# Example&#13;
**Example 1 (Singh et al.,2005)** Let $\tilde{\theta}$ be a consistent estimator of $\theta$ .For bootstrap, the distribution of $\hat{\theta}^\*-\theta$ is estimated by the bootstrap distribution $\hat{\theta}^{\*}-\hat{\theta}$ where $\tilde{\theta}^{\*}$ is the estimator of $\theta$ computed on a bootstrap sample (Efron and Tibshirani, 1993). An asymptotic CD for $\theta$ is given by $H_{n}(\theta)=1-Pr(\hat{\theta}^{\*}-\hat{\theta}\leq\hat{\theta}-\theta) = Pr(\hat{\theta}^{\*} \geq2\hat{\theta}-\theta)$ .In addition, when the limiting distribution of normalized $\tilde{\theta}$ is symmetric, the raw bootstrap distribution $H_{n}(\theta)=1-Pr(\hat{\theta}-\hat{\theta}^{\*}\leq\hat{\theta}-\theta)=Pr(\hat{\theta}^{\*}\leq\theta)$ is also an asymptotic CD.&#13;
&#13;
**Example 2** Suppose we are interested in the location parameter $\theta$ of a continuous distribution.When the distribution $F$ is symmetric, i.e., $F(\theta-y)=1-F(\theta+y)$ ， $\theta$ is the median.The Wilcoxon rank test for $H_{0}:\theta=t$ ， $H_{1}:\theta\neq t$ is based on the summation of signed ranks of $Y_{i}-t$ ,ie.,the test statistic $W=\sum_{i=1}^{n}Z_{i}R_{i}$ ,where $R_{i}$ is the rank of $\left|Y_{i}-t\right|$ ， $Z_{i}$ is an indicator variable with 1 if $Y_{i}-t&gt;0$ and -1 otherwise. Denote by $p(t)$ the $Y$ -value associated with the Wilcoxon rank test for $H_{0}:\theta=t$ ， $H_{1}:\theta\neq t$ When $t$ varies in $(-\infty,\infty)$ ,，the $P$ -value $p(t)$ is referred to as a $P$ -value function.We can prove that the $P$ -value function $p(t)$ is an asymptotic CD (Xie and Singh, 2013). Figures 2 provides illustrations of the asymptotic CD density $p^{\prime}(t)$ ,the asymptotic CD function $p(t)$ and the asymptotic CV $2min({p(t),1-p(t)\})$ for two sample sizes. The data are generated from $N(0,1)$ with sample sizes $n=10$ and 100, respectively&#13;
&#13;
&#13;
&#13;
# CD-based inference&#13;
**Point estimation The natural choices of point estimators of the parameter** Given a CD $H_n(\cdot)$, include &#13;
&#13;
(i) the median $\widetilde{\theta}_n=H_n(1/2);$ &#13;
&#13;
(ii) the mean $\bar{\theta}_{n}=\int_{\theta\in\Theta}\theta dH_{n}(\theta);$ and&#13;
&#13;
(iii) the mode $\widehat{\theta}_n=\arg\max_{\theta\in\Theta}h_n(\theta)$, where $h_n(\theta)=dH_n(\theta)/d\theta$ is the confidence density function. Under some moderate conditions, these three point estimators are consistent.&#13;
&#13;
To further understand these three types of estimators, the median $\widetilde{\theta}_{n}$ is an unbiased estimator with $\Pr_{\theta_0}(\widetilde{\theta}_n\leq\theta_0)=\Pr_{\theta_0}(1/2\leq H_n(\theta_0))=1/2;$ The mean $\bar{\theta}_n$ can be viewed as a frequentist analog of Bayesian estimator under the squared loss function; The mode $\widehat{\theta}_n$ matches with the maximum likelihood estimator if the confidence densitv is from a normalized likelihood function (Xie and Singh, 2013)&#13;
&#13;
Confidence interval As discussed in Section $\boxed2.1$, in a confidence curve, a line across the $y$-axis of the significance level $\alpha$ intersects with the confidence curve at two points, and these two points correspond to an $1-\alpha$ level, equal tailed, two-sided confidence interval for $\theta$, i.e., $(H_n^{-1}(\alpha/2),H_n^{-1}(1-\alpha/2)).$ Furthermore, $(-\infty,H_n^{-1}(1-\alpha)]$ and $[H_n^{-1}(\alpha),\infty)$ are one-sided $1-\alpha$ level confidence intervals for the parameter $\theta.$&#13;
&#13;
**Hypothesis testing** From a CD, one can obtain p-values for various hypothesis testing problems The natural thinking is to measure the support that $H_n(\cdot)$ lends to a null hypothesis (Fraser, 1991) Xie and Singh (2013) summarized making inference for hypothesis testing from a CD in the following theorem.。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/Confidence%20Distribution.html</guid><pubDate>Mon, 11 Nov 2024 09:32:31 +0000</pubDate></item><item><title>金牌就业 | 采访全文</title><link>https://DTRT4M.github.io/cjia.github.io/post/jin-pai-jiu-ye-%20-%20-cai-fang-quan-wen.html</link><description># 您是什么时候决定申请港校的？又是如何考虑的呢？&#13;
其实我一开始并没有留学的打算，一门心思想的是考研的事情。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/jin-pai-jiu-ye-%20-%20-cai-fang-quan-wen.html</guid><pubDate>Mon, 11 Nov 2024 03:46:07 +0000</pubDate></item><item><title>Bayesian Multiple Testing</title><link>https://DTRT4M.github.io/cjia.github.io/post/Bayesian%20Multiple%20Testing.html</link><description># The prior and posterior distributions&#13;
In the absence of strong prior information about $V$ and $\sigma^2$, we suggest use of&#13;
&#13;
$$\pi(V,\sigma^2)=(V+\sigma^2)^{-2}.$$&#13;
&#13;
The motivation for this choice follows from writing&#13;
&#13;
$$\pi(V,\sigma^2)=\pi(V\mid\sigma^2)\pi(\sigma^2)\equiv\frac1{\sigma^2}\left(1+\frac V{\sigma^2}\right)^{-2}\frac1{\sigma^2}.$$&#13;
&#13;
# The prior on p&#13;
An obvious objective choice of this prior is $\pi(p)=1.$ Typically, however, one does have strong prior information about $p$ and, often, this information is that $p$ is large (i.e., that most of the $\mu_i$ are zero). A convenient functional form that represents this type of information is&#13;
&#13;
$$\pi(p)=(\alpha+1)p^\alpha$$&#13;
&#13;
where $\alpha$ is an adjustable parameter allowing one to control how much of $\pi(p)’$s mass is concentrated near 1. Note the case of $\alpha=0$, which defaults back to the uniform prior.&#13;
&#13;
One simple way to specify $\alpha$ would be to make a ‘best guess’ $\hat{p}$,for $p$, and interpret this guess as the prior median. Solving for $\alpha$ leads to the choice&#13;
&#13;
$$\alpha=\frac{\log(.5)}{\log(\hat{p})}-1.$$&#13;
&#13;
As long as one does not choose $\hat{p}$ to be extremely close to 1,the resulting prior is not overly concentrated. For example, suppose the best guess for $p$ is .9,leading to $x=5.58.$ The resulting prior has fırst decile of .7,fırst quartile of .81, and third quartile of .96, reflecting a reasonable amount of variation.&#13;
&#13;
# The posterior distribution&#13;
Under the above modeling assumptions, the posterior density of $\Theta=(p,V,\sigma^{2},\gamma,\mu)$ is&#13;
&#13;
$$\pi(\Theta\mid x)=C_1^{-1}\cdot f(x\mid\sigma^2,\gamma,\mu)\cdot\left[\prod_{i:\gamma_i=1}^M\mathrm{N}(\mu_i\mid0,V)\right]\cdot\pi(\gamma\mid p)\cdot\pi(V,\sigma^2)\cdot\pi(p),$$&#13;
&#13;
where $\pi(\gamma\mid p)=\prod_{i=1}^{M}p^{1-\gamma_{i}}(1-p)^{\gamma_{i}}$ and $C_{1}$ is the normalization constant.。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/Bayesian%20Multiple%20Testing.html</guid><pubDate>Fri, 08 Nov 2024 08:15:03 +0000</pubDate></item><item><title>Multiple Testing</title><link>https://DTRT4M.github.io/cjia.github.io/post/Multiple%20Testing.html</link><description># False discovery&#13;
Consider these hypothesis testing questions:&#13;
$$H_{0j} vs H_{1j}, j=1,2...,n$$.&#13;
We want to test these an the same time, then we will receive these four results:&#13;
&#13;
Table 1:Four potential outcomes in multiple hypothesis testing&#13;
&#13;
&lt;table&gt;&#13;
	&lt;tbody&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;th&gt; &lt;/th&gt;&#13;
			&lt;th&gt;Fail to reject $H_{0}$&lt;/th&gt;&#13;
			&lt;th&gt;Reject $H_0$&lt;/th&gt;&#13;
			&lt;th&gt;Overall&lt;/th&gt;&#13;
		&lt;/tr&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;td&gt;$$H_0$$ is true&lt;/td&gt;&#13;
			&lt;td&gt;$V$&lt;/td&gt;&#13;
			&lt;td&gt;$U$&lt;/td&gt;&#13;
			&lt;td&gt;$p_0$&lt;/td&gt;&#13;
		&lt;/tr&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;td&gt;$$H_0$$ is false&lt;/td&gt;&#13;
			&lt;td&gt;$S$&lt;/td&gt;&#13;
			&lt;td&gt;$T$&lt;/td&gt;&#13;
			&lt;td&gt;$P1$&lt;/td&gt;&#13;
		&lt;/tr&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;td&gt;Overall&lt;/td&gt;&#13;
			&lt;td&gt;$p-R$&lt;/td&gt;&#13;
			&lt;td&gt;$R$&lt;/td&gt;&#13;
			&lt;td&gt;$\mathcal{D}=\mathcal{D}_{0}+\mathcal{L}$&lt;/td&gt;&#13;
		&lt;/tr&gt;&#13;
	&lt;/tbody&gt;&#13;
&lt;/table&gt;&#13;
&#13;
From this table, we could find out there are two types of error in multiple testing:&#13;
+ $p_0$ = # {Null}&#13;
+ $p_1$ = # {Alternative}&#13;
+ U = # {Fales discovery/ False postive} $\longleftarrow$ type-I error&#13;
+ S = # {False negative} $\longleftarrow$  type-II error&#13;
+ T = # {True positive}&#13;
+ R = # {Total rejection}&#13;
Therefore question is that --- How to control typr-I error?&#13;
&#13;
&#13;
&#13;
# Familywise Error Rate(FWER)&#13;
The traditional method to control gobal hypothesis test hope to strictlt control familywise error rate&#13;
$$FEWR = P(U\geq 1) \leq \alpha,$$&#13;
which means the probability of controlling for the rejection of at least one of the true original hypotheses does not exceed a given significance level $\alpha$.&#13;
&#13;
&#13;
&#13;
## Benforonni correction&#13;
&#13;
Step 1: For each hypothesis $${H_{0j}}_{j=1}^p$$, construct the test statistic $$\{T_j\}_j=1^p$$, compute the p-value $$\{p_j\}_j=1^p$$&#13;
&#13;
Step 2: For $$j=1,\cdots,p$$, reject the corresponding original hypothesis $$h_{0j}$$, if $$p_j\leq \frac{\alpha}{p}$$. &#13;
&#13;
Define $S_{0}={j:H_{0j}}$ is true , and the Benforonni correction method satisfies&#13;
&#13;
$$\text{FWER}=\mathbb{P}\left(\bigcup_{j\in S_0}\{p_j\leq\alpha/p\}\right)\leq\sum_{j\in S_0}\mathbb{P}(p_j\leq \alpha/p) = p_0 \frac{\alpha}{p}&lt;\alpha.$$&#13;
&#13;
Two flaws in the FWER criterion: &#13;
+ Theorem 1 states that the Benforonni correction will actually control the FEWR below the level of $p_0 \frac{\alpha}{p}$. The Benforonni correction is conservative when the difference between $p_0$ and $p$ is large;&#13;
+ When the scale of multiple tests $p$ is large or even divergent, the rejection threshold $\alpha/p$ of Benforonni correction degenerates and tends to cause the FWER criterion to be too strict and not to reject any hypothesis .&#13;
&#13;
Therefore, we need a new method to improve this situation.&#13;
&#13;
# False Discovery Rate&#13;
Benjamini and Hochberg(1995) suggest that set False Discovery Rate(FDR) as standard of type-I error control, rather than FWER.&#13;
&#13;
## Def (FDR):&#13;
&#13;
$$FDR \equiv E(FDP) = E\left[\frac{U}{R \vee 1}\right] ,$$&#13;
where U is Fales discovery/ False postive, T is true positive, and R is total rejections.&#13;
&#13;
Now we consider how to control FDR.&#13;
&#13;
# Benjamini-Hochberg Method&#13;
For a given FDR control level $\( q \in (0,1) \)$, the BH method's algorithm is as follows:&#13;
&#13;
**Step 1:** For the $\( p \)$-dimensional hypotheses $\( \{H_{0j}\}_{j=1}^p \)$, construct the test statistics $\( \{T_j\}_{j=1}^p \) $and calculate the corresponding p-values $\( \{p_j\}_{j=1}^p \)$.&#13;
&#13;
**Step 2:** Sort the obtained p-values in ascending order to get: $\( p_{(1)} \leq \cdots \leq p_{(p)} \)$.&#13;
&#13;
**Step 3:** Select a data-adaptive threshold value&#13;
&#13;
$$k^* = \max_{1 \leq k \leq p} \{ k : p_{(k)}{ \leq \frac{q}{p} k}};$$&#13;
&#13;
**Step 4:** For $\( j = 1, \cdots, p \), if \( p_j \leq p(k^*) \)$, reject the corresponding null hypothesis $\( H_{0j} \)$.。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/Multiple%20Testing.html</guid><pubDate>Thu, 19 Sep 2024 07:51:07 +0000</pubDate></item></channel></rss>