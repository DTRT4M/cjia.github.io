<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>Blog Title</title><link>https://DTRT4M.github.io/cjia.github.io</link><description>Blog description</description><copyright>Blog Title</copyright><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><image><url>https://github.githubassets.com/favicons/favicon.svg</url><title>avatar</title><link>https://DTRT4M.github.io/cjia.github.io</link></image><lastBuildDate>Fri, 08 Nov 2024 08:15:35 +0000</lastBuildDate><managingEditor>Blog Title</managingEditor><ttl>60</ttl><webMaster>Blog Title</webMaster><item><title>Bayesian Multiple Testing</title><link>https://DTRT4M.github.io/cjia.github.io/post/Bayesian%20Multiple%20Testing.html</link><description># The prior and posterior distributions&#13;
In the absence of strong prior information about $V$ and $\sigma^2$, we suggest use of&#13;
&#13;
$$\pi(V,\sigma^2)=(V+\sigma^2)^{-2}.$$&#13;
&#13;
The motivation for this choice follows from writing&#13;
&#13;
$$\pi(V,\sigma^2)=\pi(V\mid\sigma^2)\pi(\sigma^2)\equiv\frac1{\sigma^2}\left(1+\frac V{\sigma^2}\right)^{-2}\frac1{\sigma^2}.$$&#13;
&#13;
# The prior on p&#13;
An obvious objective choice of this prior is $\pi(p)=1.$ Typically, however, one does have strong prior information about $p$ and, often, this information is that $p$ is large (i.e., that most of the $\mu_i$ are zero). A convenient functional form that represents this type of information is&#13;
&#13;
$$\pi(p)=(\alpha+1)p^\alpha$$&#13;
&#13;
where $\alpha$ is an adjustable parameter allowing one to control how much of $\pi(p)’$s mass is concentrated near 1. Note the case of $\alpha=0$, which defaults back to the uniform prior.&#13;
&#13;
One simple way to specify $\alpha$ would be to make a ‘best guess’ $\hat{p}$,for $p$, and interpret this guess as the prior median. Solving for $\alpha$ leads to the choice&#13;
&#13;
$$\alpha=\frac{\log(.5)}{\log(\hat{p})}-1.$$&#13;
&#13;
As long as one does not choose $\hat{p}$ to be extremely close to 1,the resulting prior is not overly concentrated. For example, suppose the best guess for $p$ is .9,leading to $x=5.58.$ The resulting prior has fırst decile of .7,fırst quartile of .81, and third quartile of .96, reflecting a reasonable amount of variation.&#13;
&#13;
# The posterior distribution&#13;
Under the above modeling assumptions, the posterior density of $\Theta=(p,V,\sigma^{2},\gamma,\mu)$ is&#13;
&#13;
$$\pi(\Theta\mid x)=C_1^{-1}\cdot f(x\mid\sigma^2,\gamma,\mu)\cdot\left[\prod_{i:\gamma_i=1}^M\mathrm{N}(\mu_i\mid0,V)\right]\cdot\pi(\gamma\mid p)\cdot\pi(V,\sigma^2)\cdot\pi(p),$$&#13;
&#13;
where $\pi(\gamma\mid p)=\prod_{i=1}^{M}p^{1-\gamma_{i}}(1-p)^{\gamma_{i}}$ and $C_{1}$ is the normalization constant.。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/Bayesian%20Multiple%20Testing.html</guid><pubDate>Fri, 08 Nov 2024 08:15:03 +0000</pubDate></item><item><title>Multiple Testing</title><link>https://DTRT4M.github.io/cjia.github.io/post/Multiple%20Testing.html</link><description># False discovery&#13;
Consider these hypothesis testing questions:&#13;
$$H_{0j} vs H_{1j}, j=1,2...,n$$.&#13;
We want to test these an the same time, then we will receive these four results:&#13;
Table 1:多重假设检验中的四种潜在结果&#13;
&#13;
&lt;table&gt;&#13;
	&lt;tbody&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;th&gt; &lt;/th&gt;&#13;
			&lt;th&gt;Fail to reject $H_{0}$&lt;/th&gt;&#13;
			&lt;th&gt;Reject $H_{0}$&lt;/th&gt;&#13;
			&lt;th&gt;Overall&lt;/th&gt;&#13;
		&lt;/tr&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;td&gt;$H_{0}$is true&lt;/td&gt;&#13;
			&lt;td&gt;$V$&lt;/td&gt;&#13;
			&lt;td&gt;$U$&lt;/td&gt;&#13;
			&lt;td&gt;$p_0$&lt;/td&gt;&#13;
		&lt;/tr&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;td&gt;$\mathrm{H}_{0}$is false&lt;/td&gt;&#13;
			&lt;td&gt;$S$&lt;/td&gt;&#13;
			&lt;td&gt;$T$&lt;/td&gt;&#13;
			&lt;td&gt;$P1$&lt;/td&gt;&#13;
		&lt;/tr&gt;&#13;
		&lt;tr&gt;&#13;
			&lt;td&gt;Overall&lt;/td&gt;&#13;
			&lt;td&gt;$p-R$&lt;/td&gt;&#13;
			&lt;td&gt;$R$&lt;/td&gt;&#13;
			&lt;td&gt;$\mathcal{D}=\mathcal{D}_{0}+\mathcal{L}$&lt;/td&gt;&#13;
		&lt;/tr&gt;&#13;
	&lt;/tbody&gt;&#13;
&lt;/table&gt;&#13;
&#13;
From this table, we could find out there are two types of error in multiple testing:&#13;
+ $p_0$ = # {Null}&#13;
+ $p_1$ = # {Alternative}&#13;
+ U = # {Fales discovery/ False postive} $\longleftarrow$ type-I error&#13;
+ S = # {False negative} $\longleftarrow$  type-II error&#13;
+ T = # {True positive}&#13;
+ R = # {Total rejection}&#13;
Therefore question is that --- How to control typr-I error?&#13;
&#13;
## Familywise Error Rate(FWER)&#13;
The traditional method to control gobal hypothesis test hope to strictlt control familywise error rate&#13;
$$FEWR = P(U\geq 1) \leq \alpha,$$&#13;
which means the probability of controlling for the rejection of at least one of the true original hypotheses does not exceed a given significance level $\alpha$.&#13;
。</description><guid isPermaLink="true">https://DTRT4M.github.io/cjia.github.io/post/Multiple%20Testing.html</guid><pubDate>Thu, 19 Sep 2024 07:51:07 +0000</pubDate></item></channel></rss>